services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    environment:
      - USE_OLLAMA_DOCKER=False
      - OLLAMA_BASE_URL=http://192.168.31.179:11434
      - ENABLE_OPENAI_API=True
      - OPENAI_API_BASE_URL=http://litellm:4000/v1  # Use Stack 55 LiteLLM
      - OPENAI_API_KEY=$LITELLM_MASTER_KEY
      - ENABLE_AUTOCOMPLETE_GENERATION=False
      - ENABLE_EVALUATION_ARENA_MODELS=False
      - RAG_OPENAI_API_BASE_URL=https://api.openai.com/v1
      - RAG_EMBEDDING_ENGINE=openai
      - RAG_OPENAI_API_KEY=$OPENAI_API_KEY
      - RAG_EMBEDDING_MODEL=text-embedding-3-small
      - CHROMA_HTTP_HOST=chroma
      - ENABLE_RAG_WEB_SEARCH=True
      - RAG_WEB_SEARCH_ENGINE=searxng
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=10
      - SEARXNG_QUERY_URL=http://searxng:8080/search?q=<query>
    volumes:
      - /home/tofu/docker/open-webui:/app/backend/data
    networks:
      - openwebui
      - ai_ai  # Connect to Stack 55 LiteLLM
      
  mcpo:
    image: ghcr.io/open-webui/mcpo:main
    container_name: mcpo
    command:
      - "--config"
      - "/config/mcpo-config.json"
      - "--port"
      - "8999"
      - "--api-key"
      - $MCPO_SECRET
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/tofu/docker/mcpo/mcp:/mcp
      - /home/tofu/docker/mcpo/config/mcpo-config.json:/config/mcpo-config.json:ro
      - /mnt/IronWolf/MediaServer/Series:/MediaServer/Series
      - /mnt/IronWolf/MediaServer/Movies:/MediaServer/Movies
    environment:
      - OPENAI_API_KEY=$OPENAI_API_KEY
    ports:
      - "8999:8999"
    networks:
      - openwebui
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8999/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  chroma:
    container_name: chroma
    image: chromadb/chroma:latest
    pull_policy: always
    volumes:
      - /home/tofu/docker/volumes/chroma:/chroma/chroma
    restart: unless-stopped
    networks:
      - openwebui
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/api/v1/heartbeat || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  cloudflare:
    container_name: cloudflare_owui
    image: cloudflare/cloudflared:latest
    pull_policy: always
    restart: unless-stopped
    command: tunnel run
    networks:
      - openwebui
    environment:
      - TUNNEL_TOKEN=$TUNNEL_TOKEN
    healthcheck:
      test: ["CMD-SHELL", "cloudflared tunnel info || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  openwebui:
    driver: bridge
  ai_ai:
    external: true  # Connect to Stack 55 LiteLLM