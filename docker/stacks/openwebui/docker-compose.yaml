services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    environment:
      - USE_OLLAMA_DOCKER=False
      - OLLAMA_BASE_URL=http://${OLLAMA_HOST}:11434
      - ENABLE_OPENAI_API=True
      - OPENAI_API_BASE_URL=https://openrouter.ai/api/v1
      - OPENAI_API_KEY=${OPENROUTER_API_KEY}
      - ENABLE_AUTOCOMPLETE_GENERATION=False
      - ENABLE_EVALUATION_ARENA_MODELS=False
      - RAG_OPENAI_API_BASE_URL=https://api.openai.com/v1
      - RAG_EMBEDDING_ENGINE=openai
      - RAG_OPENAI_API_KEY=${OPENAI_API_KEY}
      - RAG_EMBEDDING_MODEL=text-embedding-3-small
      - CHROMA_HTTP_HOST=chroma
    volumes:
      - ${DATA_DIR}/open-webui:/app/backend/data
    networks:
      - openwebui
      
  mcpo:
    image: ghcr.io/open-webui/mcpo:main
    container_name: mcpo
    command:
      - "--config"
      - "/config/mcpo-config.json"
      - "--port"
      - "8999"
      - "--api-key"
      - ${MCPO_SECRET}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${DATA_DIR}/mcpo/mcp:/mcp
      - ${DATA_DIR}/mcpo/config/mcpo-config.json:/config/mcpo-config.json:ro
      - ${MEDIA_SERIES_PATH}:/MediaServer/Series
      - ${MEDIA_MOVIES_PATH}:/MediaServer/Movies
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAPI_MCP_HEADERS=${OPENAPI_MCP_HEADERS}
    ports:
      - "8999:8999"
    networks:
      - openwebui
  
  litellm:
    container_name: litellm
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    environment:
        LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
        LITELLM_SALT_KEY: ${LITELLM_SALT_KEY}
        DATABASE_URL: "postgresql://llmproxy:dbpassword9090@litellm_db:5432/litellm"
        STORE_MODEL_IN_DB: "True"
    networks:
      - openwebui

  db:
    container_name: litellm_db
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Persists Postgres data across container restarts
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - openwebui

  chroma:
    container_name: chroma
    image: chromadb/chroma:latest
    volumes:
      - ${DATA_DIR}/chroma:/chroma/chroma
    restart: unless-stopped
    networks:
      - openwebui

  cloudflare:
    container_name: cloudflare_owui
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run
    networks:
      - openwebui
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}

volumes:
  postgres_data:
    name: litellm_postgres_data

networks:
  openwebui:
    driver: bridge